
\section{Results}

\subsection{SVM results}

\subsubsection{Prediction Accuracy compared to baselines}

We trained A vs. non-A and multi-class SVMs for each of 17 courses that had at least 100 student records. We compared the 10-fold cross-validation accuracy against the average course grade and student’s GPA baselines. For the student’s GPA baseline, if a student has not taken a course before, his or her grade is predicted to be the average course grade. The results are shown in the tables below.

On average, both types of SVMs outperformed the mean course grade baseline and are comparable to the student’s GPA baseline. Overall, the multi-class SVM correctly predicts a slightly greater percentage of students within a +/- letter grade when compared to the baselines.

\begin{table}[htbp]
\caption{Average accuracy for the A vs. non-A SVMs compared to the baselines (higher is better)}
\label{svm-accuracy-table}
\begin{center}
\begin{tabular}{ll}
\multicolumn{1}{c}{\bf Predictor}  &\multicolumn{1}{c}{\bf Average Accuracy}
\\ \hline \\
A vs. non-A SVM &64.2\% \\
Student's GPA   &66.4\% \\
Mean course grade &60.6\% \\
\end{tabular}
\end{center}
\end{table}


\begin{table}[htbp]
\caption{Comparing the multi-class SVMs compared to the baselines. An error of 1 corresponds to a half letter grade error, while an error of 2 corresponds to a full letter grade error.}
\label{svm-mae-table}
\begin{center}
\begin{tabular}{lll}
\multicolumn{1}{c}{\bf Predictor}  &\multicolumn{1}{c}{\bf Average MAE}  &\multicolumn{1}{c}{\bf Within a half letter grade}
\\ \hline \\
Multi-class SVM &1.38 & 65.2\%\\
Student's GPA   &1.37 & 61.1\%\\
Mean course grade &1.45 &57.0\% \\
\end{tabular}
\end{center}
\end{table}


\subsubsection{Most important features}

We evaluated the contribution of each set of features by training the A vs. non-A SVM exclusively on each set  and comparing the 10-fold cross-validation accuracies against the baseline statistical accuracy.

Overall, the top four features in order were previous course history, recent grades by department, student’s major, and concurrent courses. Weekly workload did not contribute to the accuracy of any of the selected courses, and the number of taken courses only influenced accuracy in CS161 out of the 17 courses tested.

However, across different courses, the features that most influenced prediction accuracy varied. For example, in CS161, all of the features except for weekly workload contributed to the prediction rate, and the student’s previous course grades were the most significant predictor. On the other hand, in ARTSTUDI60, the student’s major was the most significant predictor. In CHEM31A, none of the features contributed to the accuracy, suggesting that different factors may better characterize course grades in this case.

\begin{table}[t]
\caption{Percent accuracy increases for A vs. non-A SVM when including only one of the feature types. The largest contributer for each course is highlighted.}
\label{svm-features-table}
\begin{center}
\begin{tabular}{lllllll}
\multicolumn{1}{c}{\bf Course}  &\multicolumn{1}{c}{\bf Dept. GPA} &\multicolumn{1}{c}{\bf Concurr. courses} &\multicolumn{1}{c}{\bf Course grades} &\multicolumn{1}{c}{\bf Major} &\multicolumn{1}{c}{\bf Workload} &\multicolumn{1}{c}{\bf Num. Prev. Courses}
\\ \hline \\
ARTSTUDI60&	0&	1.83&	1.83& \cellcolor[gray]{0.8}5.50&	0&	0\\
CHEM31A	& 0	& 0 &	0 &	0 &	0&	0\\
CHEM33&\cellcolor[gray]{0.8}	3.11&	0.35&	1.29&	0.09&	0&	0\\
CS105&	0.17&	0.50&\cellcolor[gray]{0.8}2.67&	0.50&	0&	0\\
CS106A&	0.63&	0.00&	1.40&\cellcolor[gray]{0.8}	3.29&	0&	0\\
CS161	&10.21&	8.80&\cellcolor[gray]{0.8}16.90&	5.99&	0&	11.27\\
CS229	&0&\cellcolor[gray]{0.8}	1.96&	0&	0&	0&	0\\
EE108B&	0&\cellcolor[gray]{0.8}	1.86&	0&	1.24&	0&	0\\
HUMBIO2A&	0.31&	0&\cellcolor[gray]{0.8}	6.16&	0&	0&	0\\
HUMBIO2B&	5.24&	0&\cellcolor[gray]{0.8}	7.26&	0&	0&	0\\
IHUM2&\cellcolor[gray]{0.8}	7.99&	1.91&	6.25&	5.90&	0&	0\\
IHUM57&	0&\cellcolor[gray]{0.8}	1.01&	0&	0&	0&	0\\
IHUM63&	0&\cellcolor[gray]{0.8}	0.66&	0&	0&	0&	0\\
MATH42&\cellcolor[gray]{0.8}	4.40&	0&	0.51&	0&	0	&0\\
PHYSICS43&	4.93&	1.15&\cellcolor[gray]{0.8}	5.92&	1.15&	0&	0\\
PSYCH1&\cellcolor[gray]{0.8}	1.67&	1.12&	1.12&	1.49&	0&	0\\
POLISCI1&	0.34&	1.02&\cellcolor[gray]{0.8}	3.07&	2.39&	0&	0\\
\\ \hline \\
Average &2.29&	1.30&	3.20&	1.62&	0.00&	0.66\\


\end{tabular}
\end{center}
\end{table}

\subsection{Collaborative Filtering results}



\section{Conclusion and Future Work}

Past course history can only go so far in predicting future course grades. A significant percentage of students in many of the courses had not taken any courses previously, which may partially explain the low accuracy of the baselines and the SVMs. In addition, there may be more promising features that characterize the current quarter if course schedule data were available, such as potential schedule and deadline conflicts between concurrent courses and student activities. Although the concurrent courses features was intended to help capture some of the effects of schedule conflict, it is flawed in that most courses do not have a fixed schedule and instead change term by term. Thus courses that have conflicted in the past may not conflict in the future.

It is also possible that the unexpected occurrences throughout the quarter may have greater influence on grades. For example, a student may just not have studied enough for a final exam, which heavily influences his or her grade. Individual personality factors may also play a part, where doing poorly on a similar course in the past may drive some students to work harder on a similar course in the future.

For collaborative filtering, we could broaden our hypothesis and, for a student $s$ and course $c$, try try to find students that have not only taken the same courses as $s$ an also taken $c$, but who have taken similar courses to both $c$ and courses similar to those taken by $s$.  This can help overcome the sparsity of the data, which is evidenced by the high correlation of the collaborative filtering results to the student average baseline estimate.  Some work at combining user-based and item-based collaborative filtering has been investigated in \cite{fusion}.
