\subsection{Collaborative filtering}

We consider another model for estimating grades based on the same methods used in the original recommendation system.  Here, we make the hypothesis that similar students will make similar grades.  Thus, for a student $s$ with course history $C_s$ and course $c \notin C_s$, we find students $s_i \in S$ with $|C_{s_i} \cup C_s| > 0$ and $c \in C_{s_i}$ (students who have taken some of the same courses as $s$ as well as course $c$).  Then $u$'s grade in $c$ can be estimated as a weighted average of the grades $g_{s_i}$.  

To determine the relative weights of users, we used cosine similarity and Pearson's correlation as the primary two measures.  Other measures of similarity such as Kendall, Spearman, and adjusted cosine similarity have been explored in~\cite{herlocker} and~\cite{yu}, but they tend to perform similarly or worse.  We expect our choice of similarity will have little impact on the predicted grades.

For two student (sparse) vectors $S_a$ and $S_b$ with each element corresponding to the student's grade in a course, the similarity is computed using:

\begin{center}
\begin{tabular}{cc}
$\textrm{similarity} = \frac{S_a \cdot S_b}{\|S_a\|\|S_b\|}$
&
$\textrm{Pearson's} = \frac{\textrm{cov}(S_a, S_b)}{\sigma_{S_a}\sigma_{S_b}} = \frac{\sum ^n _{i=1}(S_{a}^{(i)} - \overline{S}_a)(S_{b}^{(i)} - \overline{S}_b)}{\sqrt{\sum ^n _{i=1}(S_a^{(i)} - \overline{S}_a)^2} \sqrt{\sum ^n _{i=1}(S_b^{(i)} - \overline{S}_b)^2}}$.
\end{tabular}
\end{center}

Grade predictions for CF follow the multiclass SVM model with 1: A+, 2: A, 3: A-, $\ldots$, 13: F.

For CF, data was initially filtered to remove all courses with fewer than 3 grades and all students with fewer than 4 courses.  This resulted in 5930 students and 3603 courses.  For testing the whole dataset, we separated $10\%$ of the students to test with 3 courses in their transcript removed.  Each student was compared with the other 5337 students to compute the $n$ most similar students.  We tried various values of $n$ from all students to $5$.  $n=10$ produced the lowest MAE, but the variation in MAE was less than 0.2, meaning the choice of $n$ had very little impact on the final predictions.  We also tried removing the influence of negatively correlated students as both Herlocker and Yao indicate that this improves error.  This further reduces the MAE, but again, not enough to significantly change predicted grades.  

The weighted average makes the assumption that student grades follow approximately the same distribution~\cite{herlocker}.  This assumption might not be valid for our data.  

We could also broaden our hypothesis: for student $s$ and course $c$, look for users that have not only taken the same courses as the user in question, but who have taken similar courses to those  
