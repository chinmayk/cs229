\documentclass{article} % For LaTeX2e
\usepackage{nips10submit_e,times}
%\usepackage{xcolor}
\usepackage{colortbl}
%\documentstyle[nips10submit_09,times,art10]{article} % For LaTeX 2.09


\title{Predicting Course Grades}


\author{
Martin Hunt, Sharon Lin, Chinmay Kulkarni \\
\texttt{ \{chinmay, mghunt, sharonl\}@stanford.edu}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
Recommendation systems have been used in a variety of domains, ranging from online-joke recommendations to automatic educational course recommendations.
To better evaluate recommendations, the user can be presented with estimations for the various attributes of a recommendation. We attempt to construct one particular potential value-predictor: the estimated grade a student will receive for a given course. Data is from the CourseRank recommendation system.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Recommendation systems attack the general problem of recommending users items that are likely to be of interest to them. This is typically viewed as a problem of predicting the ``rating'' of a given item, based on known ratings of other items, followed by finding items that have the highest ratings. Recommendation systems have been used in a variety of applications, and depending on the application, the \textit{items} could be physical goods, movies, research papers, webpages, educational courses, etc~\cite{schafer1999recommender}. Similarly, the \textit{ratings} could either be explicitly provided by the user (e.g. using a 1-to-5 star rating, or a Likert scale), or obtained implicitly by the system (e.g. the number of times a webpage was visited).

Recommendation systems are primarily either model-based or memory-based. A model-based system abstracts a model that predicts ratings for a given user and item. A memory-based system uses unsupervised learning to cluster user-item data (either the users or the items may be clustered) based on the known ratings. An unknown rating is then approximated with a weighted average of known ratings, the weight being the distance of the unrated item and the rated items. Memory-based systems have been particularly popular, since they makes fewer assumptions regarding what factors contributed to a rating, and are more likely to produce diverse recommendations than a model-based approach. 

While recommendation systems recommend a set of items to a user, the user still has to evaluate these recommendations in order to find the most useful ones. In this paper, we explore how users can be assisted in this task. One particular aspect that we focus on is value prediction for item-attributes. This is useful for answering questions such as, ``how \textit{suspenseful} is this recommended movie?'', or ``how \textit{important} is this research paper?''. 

We think value prediction for item-attributes is especially useful for a) attributes whose values vary by user (e.g. ``interestingness'' for a book) b) attribute values that can only be measured after the item is consumed (e.g. ``durability'' for furniture) and c) attributes that may change based on whether the user has consumed other items (e.g. ``understandability'' for movie sequels [TODO less cheesy examples?]) 

In our system, the exemplar question we try to answer is ``what \textit{grade} will I make?'' for a University course recommendation. Course grades (fortunately) have all the above characteristics: the grade varies by user, is only available after the course is taken and potentially depends on other courses the student has taken in the past.

\section{Prior work}
Memory-based recommendation systems make the assumption that users who have rated items similarly (i.e. favorably or unfavorably) in the past will also rate a new item similarly, so these systems typically expose, in addition to the recommended item, either other similar items the user has rated favorably in the past, or other users with tastes similar to the current user who rated the recommended item favorably. This information helps users trust recommendations~\cite{o2005trust, adomavicius2005toward}, we argue that it still does not help them directly evaluate them for two reasons.

First, exposing similar items often provides no information about attribute values-- for instance, if a user is buying furniture and has rated furniture that was durable favorably in the past, the system cannot predict durability, despite showing that the current recommendation is ``similar'' to his past purchases. 

Second, even if information is provided, human perception of similarity is non-metric, so humans still can't accurately estimate attributes values. In particular, similarity perception is not symmetric (for instance, China is perceived to be more similar to North Korea than North Korea is to China), and it does not follow the triangle-inequality (similarity of (A with B) + (B with C) could be less than A with C)~\cite{tversky1982similarity}.

Model-based approaches have problems with evaluation too. Models are often based on Bayesian networks, LSA or MDPs-- while these models have good accuracy, they can't predict attributes they weren't trained for [TODO can someone rephrase?].

\section{Predicting grades}
Our data is drawn from the CourseRank website, which is a course-recommendation website run at Stanford.


\input{svm}

\subsection{Collaborative filtering}


%Need to add CF stuff to results and conclusions
\input{resultsconclusions}




%sample is the nips sample formatting guidlines, comment out when not needed anymore

%\input{sample}
\bibliographystyle{abbrv}
\bibliography{refs}
\end{document}
