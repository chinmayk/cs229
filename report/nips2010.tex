\documentclass{article} % For LaTeX2e
\usepackage{nips10submit_e,times}
%\usepackage{xcolor}
\usepackage{url}
\usepackage{colortbl}
%\documentstyle[nips10submit_09,times,art10]{article} % For LaTeX 2.09


\title{Predicting Course Grades}


\author{
Martin Hunt, Sharon Lin, Chinmay Kulkarni \\
\texttt{ \{chinmay, mghunt, sharonl\}@stanford.edu}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
Recommendation systems have been used in a variety of domains, ranging from online-joke recommendations to automatic educational course recommendations (CourseRank). However, users may want different recommendations for different reasons.
In order to help each user select the recommendation that aligns best with his or her goals and values, a recommendation system can present users with estimations of various attributes of a particular recommendation.  Using the data from the CourseRank recommendation system, we attempt to construct one potential value-predictor: the estimated grade a student will receive for a given course.  Both SVMs and collaborative filtering techniques performed well, but neither could provide significantly better grade predictions than a baseline estimate of the average grade for each student.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Recommendation systems attack the general problem of recommending users items that are likely to be of interest to them. This is typically viewed as a problem of predicting the ``rating'' of a given item, based on known ratings of other items, followed by finding items that have the highest ratings. Recommendation systems have been used in a variety of applications, and depending on the application, the \textit{items} could be physical goods, movies, research papers, webpages, educational courses, etc~\cite{schafer1999recommender}. Similarly, the \textit{ratings} could either be explicitly provided by the user (e.g. using a 1-to-5 star rating, or a Likert scale), or obtained implicitly by the system (e.g. the number of times a webpage was visited).

Recommendation systems are primarily either model-based or memory-based. A model-based system abstracts a model that predicts ratings for a given user and item. A memory-based system uses unsupervised learning to cluster either user or item data based on the known ratings. An unknown rating is then approximated with a weighted average of known ratings, the weight being the distance of the unrated item and the rated items. Memory-based systems have been particularly popular, since they makes fewer assumptions regarding what factors contributed to a rating, and are more likely to produce diverse recommendations than a model-based approach. 

However, users may have specific needs for recommendations that are not covered well by an overall goodness score or ranking. In these cases, the user still has to evaluate the given set of recommendations in order to find the most useful ones for his or her purposes. In this paper, we explore how users can be assisted in this task. One particular aspect that we focus on is value prediction for more specific item-attributes. This is useful for answering questions such as, ``how \textit{suspenseful} is this recommended movie?'', or ``how \textit{important} is this research paper?''. 

%We think value prediction for item-attributes is especially useful for a) attributes whose values vary by user (e.g. ``interestingness'' for a book) b) attribute values that can only be measured after the item is consumed (e.g. ``durability'' for furniture) and c) attributes that may change based on whether the user has consumed other items (e.g. ``understandability'' for movie sequels [TODO less cheesy examples?]) 

In our system, the exemplar question we try to answer is ``what \textit{grade} will I make?'' for a University course recommendation. Course grades are particularly interesting because they vary by student and may be different depending on when the course is taken. We use both SVM and a collaborative filtering-based approaches to predict student grades based on student transcript and schedule data.


%Course grades (fortunately) have all the above characteristics: the grade varies by user, is only available after the course is taken and potentially depends on other courses the student has taken in the past.


%Maybe merge some of the below material in previous work with the intro? 

%\section{Prior work}
%Memory-based recommendation systems make the assumption that users who have rated items similarly (i.e. favorably or unfavorably) in the past will also rate a new item similarly. These systems typically expose, in addition to the recommended item, either other similar items the user has rated favorably in the past, or other users with tastes similar to the current user who rated the recommended item favorably. Although this information helps users trust recommendations~\cite{o2005trust, adomavicius2005toward}, we argue that it still does not help them directly evaluate them for two reasons.

%First, exposing similar items often provides no information about attribute values-- for instance, if a user is buying furniture and has rated furniture that was durable favorably in the past, the system cannot predict durability, despite showing that the current recommendation is ``similar'' to his past purchases.
%Second, even if information is provided, human perception of similarity is non-metric, so humans still can't accurately estimate attributes values. In particular, similarity perception is not symmetric (for instance, China is perceived to be more similar to North Korea than North Korea is to China), and it does not follow the triangle-inequality (similarity of (A with B) + (B with C) could be less than A with C)~\cite{tversky1982similarity}.

%Model-based approaches have problems with evaluation too. Models are often based on Bayesian networks, LSA or MDPs-- while these models have good accuracy, they can't predict attributes they weren't trained for [TODO can someone rephrase?].

\section{Predicting Grades}
Our data is drawn from the CourseRank website, which is a course-recommendation website run at Stanford. The CourseRank database contains information on 10,000 anonymized student transcripts and around 7,000 courses.

\input{svm}
\input{cf}

%Need to add CF stuff to results and conclusions
\input{resultsconclusions}

%sample is the nips sample formatting guidlines, comment out when not needed anymore

%\input{sample}
\bibliographystyle{abbrv}
\bibliography{refs}
\end{document}
